{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import resample\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train = pd.read_excel(\"/home/rafael/Documentos/FACOM/Douturado/Doutorado/webcrawler/medicamentos.xlsx\",index_col=0,dtype=str)\n",
    "df_train.head()\n",
    "list_preprossing=[]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for dta in range(df_train.shape[0]):\n",
    "    value=str(df_train.iloc[dta,1])\n",
    "    # value=str(df_train.iloc[dta,0])+\" \"+str(df_train.iloc[dta,1]) +\" \"+str(df_train.iloc[dta,2])+\" \"+str(df_train.iloc[dta,3])\n",
    "    list_preprossing.append(value)\n",
    "list_preprossing=np.array(list_preprossing)\n",
    "print(list_preprossing)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(list_preprossing)\n",
    "print(list_preprossing.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('distilbert-base-nli-mean-tokens',device='cuda')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpus_embeddings = embedder.encode(list_preprossing,show_progress_bar=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for data in corpus_embeddings:\n",
    "    print(data.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tsne = TSNE(random_state = 42, n_components=2)\n",
    "pca = PCA(n_components=2)\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embeddings2d_pca = pca.fit_transform(corpus_embeddings)\n",
    "# embeddings2d_lda = lda.fit_transform(corpus_embeddings,list_preprossing)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_4 = KMeans(n_clusters=4,n_init=40)\n",
    "modelo_knn_3 = knn_4.fit_predict(embeddings2d_pca)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_name =list(df_train.iloc[:,0])#lista com os nomes do medicamento\n",
    "# print(list_name)\n",
    "# print(modelo_knn_3)\n",
    "classes=[] #dicionario para armazenar a classe. key(medicamento):value(classe)\n",
    "color = {0:'.b',1:'.r',2:'.c',3:'.y',4:'xb',5:'xr',6:'xc',7:'xy',8:'xk',9:'xb',10:'xr',11:'xc',12:'xy',13:'xk'} #dicionario  de classe e cores\n",
    "colors=[ color[x] for x in modelo_knn_3] # modelo_knn_3 retorna uma lista de valores [2,1,3,4]\n",
    "fig,ax = plt.subplots(1,figsize=(10,10))\n",
    "for i, cl_xy in enumerate(zip(colors,embeddings2d_pca)): #embeddings2d possui x e y\n",
    "    cl=cl_xy[0]\n",
    "    xy=cl_xy[1]\n",
    "    ax.plot(xy[0],xy[1],cl)\n",
    "    # print(df_train.iloc[i].name)\n",
    "    classes.append({'nome':df_train.iloc[i].name,'ativo':list_name[i],\"classes\":df_train['classes'].iloc[i],\"classe_pred\":modelo_knn_3[i]})\n",
    "    # classes.append({'nome':df_train.iloc[i].name,'ativo':list_name[i],\"classes\":df_train['classes'].iloc[i],\"classe_pred\":modelo_knn_3[i]})\n",
    "\n",
    "# for i, cl_xy in enumerate(zip(colors,embeddings2d)): #embeddings2d possui x e y\n",
    "#     cl=cl_xy[0]\n",
    "#     xy=cl_xy[1]\n",
    "#     ax.plot(xy[0],xy[1],cl)\n",
    "#     print(df_train.iloc[i].name)\n",
    "#     classes.append({'nome':df_train.iloc[i].name,'ativo':list_name[i],\"classes\":df_train['classes'].iloc[i],\"classe_pred\":modelo_knn_3[i]})\n",
    "fig.savefig('my_plot.png')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "frame_result = pd.DataFrame(classes).sort_values(\"classe_pred\",axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docs_df = pd.DataFrame(list_preprossing,columns=[\"Doc\"])\n",
    "docs_df['Topico'] = modelo_knn_3\n",
    "docs_df['Doc_ID'] = range(len(docs_df))\n",
    "docs_per_topic=docs_df.groupby([\"Topico\"],as_index=False).agg({\"Doc\":' '.join})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
    "    count = CountVectorizer(ngram_range=ngram_range, stop_words=\"english\").fit(documents)\n",
    "    t = count.transform(documents).toarray()\n",
    "    w = t.sum(axis=1)\n",
    "    tf = np.divide(t.T, w)\n",
    "    sum_t = t.sum(axis=0)\n",
    "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
    "    tf_idf = np.multiply(tf, idf)\n",
    "\n",
    "    return tf_idf, count\n",
    "\n",
    "tf_idf, count = c_tf_idf(docs_per_topic.Doc.values, m=len(data))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20):\n",
    "    words = count.get_feature_names()\n",
    "    labels = list(docs_per_topic.Topic)\n",
    "    tf_idf_transposed = tf_idf.T\n",
    "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
    "    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
    "    return top_n_words\n",
    "\n",
    "def extract_topic_sizes(df):\n",
    "    topic_sizes = (df.groupby(['Topico'])\n",
    "                   .Doc\n",
    "                   .count()\n",
    "                   .reset_index()\n",
    "                   .rename({\"Topico\": \"Topico\", \"Doc\": \"Size\"}, axis='columns')\n",
    "                   .sort_values(\"Size\", ascending=False))\n",
    "    return topic_sizes\n",
    "\n",
    "top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20)\n",
    "topic_sizes = extract_topic_sizes(docs_df); topic_sizes.head(10)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topic_sizes"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
